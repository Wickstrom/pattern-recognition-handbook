{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering 1 - Sequential clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "- Often important to find groups in data.\n",
    "- Vastly important in data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "- Consider the following directed graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "- Consider the following directed graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: Science or Art?\n",
    "\n",
    "- - [**Is there such a thing as a \"correct\" clustering?**](https://proceedings.mlr.press/v27/luxburg12a/luxburg12a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Key points\n",
    "\n",
    "- Often no prior knowledge about data -> unsupervised\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Idea 2\n",
    "\n",
    "- Count ranks associated with backlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Remarks to idea 2\n",
    "\n",
    "- Ranking becomes maths!\n",
    "- Unlogical \"recommendation\" process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Idea 3\n",
    "\n",
    "- Multiple recommendations sum to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Idea 3 in matrix-vector form\n",
    "\n",
    "- Let $$ \\mathbf{H}^T = \\begin{bmatrix} 0 & 0 & 1 & \\frac{1}{2} \\\\ \\frac{1}{3} & 0 & 0 \\\\ \\frac{1}{3} & \\frac{1}{2} & 0 & \\frac{1}{2} \\\\ \\frac{1}{3} & \\frac{1}{2} & 0 & 0 \\end{bmatrix}$$\n",
    "- and $$ \\boldsymbol{\\Pi} = \\begin{bmatrix} r_1 \\\\ r_2 \\\\ r_3 \\\\ r_4 \\end{bmatrix}$$\n",
    "- Hence: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Note on idea 3\n",
    "\n",
    "- $\\boldsymbol{\\Pi}$ is an eigenvector of $\\mathbf{H}^T$ for $\\lambda = 1$\n",
    "- World's most famous eigenvector\n",
    "- Google PageRank alogirthm (with some modifications)\n",
    "- Solution: $$ \\boldsymbol{\\Pi} = \\begin{bmatrix} 0.4 \\\\ 0.1 \\\\ 0.3 \\\\ 0.2 \\end{bmatrix}$$\n",
    "- Alternatively: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Google as a Markov chain\n",
    "\n",
    "- $\\mathbf{H}$ is special!\n",
    "    - Transition matrix in (homogeneous, discrete) Markov chain\n",
    "- $$ \\mathbf{H} = \\begin{bmatrix} 0 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\\\ 1 & 0 & 0 & 0 \\\\ \\frac{1}{2} & 0 & \\frac{1}{2} & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Google as a Markov chain\n",
    "\n",
    "- $\\boldsymbol{\\Pi}$ has a special meaning\n",
    "- Theorem: If $\\mathbf{H}: H_{ij}=p_{ij}$ is a transition matrix and $0 \\lt p_{ij} \\lt 1$ then\n",
    "    - $\\lambda_{max}=1$\n",
    "    - $\\boldsymbol{\\Pi}_{max}$ is unique, positive, sums to one.\n",
    "    - $\\boldsymbol{\\Pi}_{max}$ can always be found by the power method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov chain example\n",
    "\n",
    "- $$ \\mathbf{A}(\\mathbf{H}^T) = \\begin{bmatrix} 0.3 & 0.4 & 0.5 \\\\ 0.3 & 0.4 & 0.3 \\\\ 0.4 & 0.2 & 0.2 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov chain example\n",
    "\n",
    "- Find:\n",
    "    - P(start @ C, end @ B after 2 deliveries)\n",
    "- $P(CA)P(AB)+P(CB)P(BB)+P(CC)P(CB)=0.33$\n",
    "- $$ \\begin{bmatrix} 0.41 & 0.38 & 0.37 \\\\ 0.33 & 0.34 & 0.33 \\\\ 0.26 & 0.28 & 0.30 \\end{bmatrix} = \\mathbf{A}\\mathbf{A}=\\mathbf{A}^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov chain example\n",
    "\n",
    "- Probablities after 5 and 6 steps:\n",
    "- $$ \\mathbf{A}^5 \\approx \\mathbf{A}^6 \\approx \\begin{bmatrix} 0.39 & 0.39 & 0.39 \\\\ 0.33 & 0.33 & 0.33 \\\\ 0.28 & 0.28 & 0.28 \\end{bmatrix} $$\n",
    "- Converges!\n",
    "- Stationary distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov chain example\n",
    "\n",
    "- Eigenvector:\n",
    "    - Let $\\mathbf{x}^{(0)}$ be our starting rank.\n",
    "- Update rank for each step in the chain.\n",
    "- Show ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The power method\n",
    "\n",
    "- Iterative; finds dominant eigenvector\n",
    "- Scaling after iteration in general.\n",
    "- Markov example:\n",
    "    - $\\mathbf{x}^T = [0.39, 0.33, 0.28]$ is the stationary distribution off the states in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea 4\n",
    "\n",
    "- Modify $\\mathbf{H}$ such that $0 \\lt p_{ij} \\lt 1$.\n",
    "- Modification 1; Dangling nodes (no outlinks) creates zero rows in $\\mathbf{H}$\n",
    "- $$ \\mathbf{H}^T = \\begin{bmatrix} 0 & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 \\\\ 1 & 0 & 0 & 0 & 0 \\\\ \\frac{1}{2} & 0 & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\end{bmatrix}$$\n",
    "- Replace zero row with row of 1/n probablities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modification 2\n",
    "\n",
    "- Google matrix: $$ \\mathbf{G} = \\alpha \\mathbf{S} + (1-\\alpha)\\mathbf{E}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretation $(\\alpha=0.85)$\n",
    "\n",
    "- 85% of the time, surfer follow links.\n",
    "- 15% of the time, surfer types URL (teleportation).\n",
    "- Personalization:\n",
    "    - $\\frac{1}{n}\\mathbf{e}\\mathbf{e}^T \\rightarrow \\mathbf{e}\\mathbf{v}^T$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Final remarks\n",
    "\n",
    "- $\\mathbf{H}$ is sparse (good).\n",
    "- $\\mathbf{G}$ is dense but function of $\\mathbf{H}$\n",
    "- Power method is nice! (no inverse)\n",
    "- Early report from Google indicated 50 iterations.\n",
    "- Updated on a frequent basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Programming exercises\n",
    "\n",
    "No programming exercises for this lecture\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
