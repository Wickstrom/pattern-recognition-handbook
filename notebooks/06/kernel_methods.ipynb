{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Non-linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "- For the final part of non-linear classifiers, we will see how we can turn SVM into non-linear classifiers.\n",
    "- Heavily depends on a field of research known as **kernel methods**.\n",
    "- A field of its own with lots of usecases throughout machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remembering SVMs\n",
    "\n",
    "- **Recall:**  From $L(\\mathbf{w}, w_0)$: $$\\mathbf{w} = \\sum_{i \\in SV} \\lambda_i y_i \\mathbf{x}_i$$\n",
    "\n",
    "- **Dual:**  $$ \\max_{\\lambda \\geq 0} \\sum_{i=1}^N \\lambda_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle$$\n",
    "\n",
    "- Subject to: $$ \\sum_i \\lambda_i y_i = 0$$\n",
    "- Note: $\\langle \\mathbf{x}_i, \\mathbf{x} \\rangle$ denotes the inner\n",
    "\n",
    "---\n",
    "\n",
    "- **In testing:** $$ g(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + w_0 = \\sum_{i \\in SV} \\lambda_i y_i \\langle \\mathbf{x}_i, \\mathbf{x} \\rangle + w_0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Programming exercises\n",
    "\n",
    "Below are programming exercises assocaited with this lecture. These cell blocks are starting points that loads the data and prepares the problem such that you can get going with the implementation. There are also theoretical exercsies, but due to copyright we cannot shared them here. They will be made available in a private repository connected to the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-linear classification with a SVM\n",
    "\n",
    "The code below loads a classic synthetic machine learning dataset, the Two Moons dataset, that we have looked at before. Traing a SVM with a non-linear kernel to tackle this non-linearly separable classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.15, random_state=42)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wine classification with SVM\n",
    "\n",
    "This problem is revisting the Wine classification problem from the linear SVM notebook. Now, turn the SVM into a non-linear classifier through a Gaussian kernel. How does this affect performance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# fetch dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = wine_data.data[:, :2]\n",
    "feature_1_name = 'alcohol'\n",
    "feature_2_name = 'malic acid'\n",
    "y = wine_data.target\n",
    "y_names = np.unique(y)  # class names\n",
    "colors = ['black', 'blue', 'red']\n",
    "\n",
    "plt.figure(1, figsize=(5, 5))\n",
    "for class_value, color in zip(y_names, colors):\n",
    "    plt.scatter(X[y == class_value, 0], X[y == class_value, 1], s=120, facecolors='none',\n",
    "                edgecolors=color, linewidth=3.0, label=f'Class {class_value+1}')\n",
    "plt.xlabel(feature_1_name)\n",
    "plt.ylabel(feature_2_name)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "sta2003_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "403px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
